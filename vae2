import math

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
from torchvision import transforms
from customDataset import PartDataset
import matplotlib.pyplot as plt
from torch.utils.tensorboard import SummaryWriter
model_number = 9
latent_size = int(10)
writer = SummaryWriter("C:/Users/William/Desktop/images/tb/tb{}".format(model_number))


class VAE(nn.Module):

    def __init__(self):
        super().__init__()
        # N, 1, 128, 128
        self.CNN_encoder_0 = nn.Sequential(
            nn.Conv2d(1, 16, 3, stride=2, padding=1),  # N, 16, 64,64
            nn.ReLU())

        self.max_pool_1 = nn.MaxPool2d(2, return_indices=True)  # N, 16, 32,32
        self.CNN_encoder_1 = nn.Sequential(
            nn.BatchNorm2d(16),
            nn.Dropout(0.2),
            nn.Conv2d(16, 32, 3, stride=2, padding=1),  # N, 32, 16,16
            nn.ReLU())

        self.max_pool_2 = nn.MaxPool2d(2, return_indices=True)  # N, 32, 8,8
        self.CNN_encoder_2 = nn.Sequential(
            nn.BatchNorm2d(32),
            nn.Dropout(0.2),
            nn.Conv2d(32, 64, 3, stride=2, padding=1),  # N, 64, 4,4
            nn.ReLU())

        self.max_pool_3 = nn.MaxPool2d(2, return_indices=True)  # N, 64, 2,2
        self.CNN_encoder_3 = nn.Sequential(
            nn.BatchNorm2d(64),
            nn.Dropout(0.2),
            nn.Conv2d(64, 128, 2),  # N, 128, 1,1
            nn.ReLU(),
            nn.BatchNorm2d(128),
            nn.Dropout(0.2)
        )
        # 512
        self.linear_encoder = nn.Sequential(
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.BatchNorm1d(64),
            nn.Dropout(0.2),
            nn.Linear(64, 20),
            nn.ReLU(),
            nn.BatchNorm1d(20),
            nn.Dropout(0.2)
        )

        self.linear_decoder = nn.Sequential(
            nn.Linear(10, 64),
            nn.ReLU(),
            nn.BatchNorm1d(64),
            nn.Dropout(0.2),
            nn.Linear(64, 128),
            nn.ReLU(),
            nn.BatchNorm1d(128),
            nn.Dropout(0.2)
        )

        self.CNN_decoder_0 = nn.Sequential(
            nn.ConvTranspose2d(128, 64, 2),  # N, 64, 2,2
            nn.ReLU())
        self.max_unpool_1 = nn.MaxUnpool2d(2)
        self.CNN_decoder_1 = nn.Sequential(
            nn.BatchNorm2d(64),
            nn.Dropout(0.2),
            nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1),  # N, 32, 32,32
            nn.ReLU())
        self.max_unpool_2 = nn.MaxUnpool2d(2)
        self.CNN_decoder_2 = nn.Sequential(
            nn.BatchNorm2d(32),
            nn.Dropout(0.2),
            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),  # N, 16, 64,64
            nn.ReLU())
        self.max_unpool_3 = nn.MaxUnpool2d(2)
        self.CNN_decoder_3 = nn.Sequential(
            nn.BatchNorm2d(16),
            nn.Dropout(0.2),
            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),  # N, 1, 128, 128
            nn.Sigmoid()
        )


    def reparameterise(self, mu, logvar):
        if self.training:
            std = logvar.mul(0.5).exp_()
            eps = std.data.new(std.size()).normal_()
            return eps.mul(std).add_(mu)
        else:
            return mu

    def encode(self, x):

        features = self.CNN_encoder_0(x.view(-1, 1, 128, 128))
        features, indices_3 = self.max_pool_1(features)
        features = self.CNN_encoder_1(features)
        features, indices_2 = self.max_pool_2(features)
        features = self.CNN_encoder_2(features)
        features, indices_1 = self.max_pool_3(features)
        features = self.CNN_encoder_3(features)
        features = features.flatten(start_dim=1)

        mu_logvar = self.linear_encoder(features)
        mu_logvar = mu_logvar.view(-1, 2, latent_size)

        mu = mu_logvar[:, 0, :]
        logvar = mu_logvar[:, 1, :]
        return mu, logvar, indices_1, indices_2, indices_3




    def decode(self, z, indices_1, indices_2, indices_3):
        features = self.linear_decoder(z.view(-1, 10))
        features = features.view(-1, 128, 1, 1)
        features = self.CNN_decoder_0(features)
        features = self.max_unpool_1(features, indices_1)
        features = self.CNN_decoder_1(features)
        features = self.max_unpool_2(features, indices_2)
        features = self.CNN_decoder_2(features)
        features = self.max_unpool_3(features, indices_3)
        x_hat = self.CNN_decoder_3(features)
        return x_hat

    def forward(self, x):
        mu, logvar, indices_1, indices_2, indices_3 = self.encode(x)
        z = self.reparameterise(mu, logvar).view(-1, 10, 1, 1)
        xhat = self.decode(z, indices_1, indices_2, indices_3)

        return xhat, mu, logvar
    # def sample(self, n_samples):
    #     z = torch.randn((n_samples, latent_size)).to(device)
    #     return self.decode(z)

# Hyperparameters
num_epochs = 1000
batch_size = 32
# lr = 0.002
optimizer_cls = optim.Adam
lr = 0.002


# Load data
dataset = PartDataset(csv_file="C:/Users/William/Desktop/set 1/set1.csv", root_dir='C:/Users/William/Desktop/set 1/images')# transform=transforms.ToTensor()

trainset, testset = torch.utils.data.random_split(dataset, [1000, 300])
test_loader = torch.utils.data.DataLoader(dataset=testset, shuffle=True, batch_size=batch_size, num_workers=0)
train_loader =torch.utils.data.DataLoader(dataset=trainset, shuffle=True, batch_size=batch_size, num_workers=0, drop_last=False)
# Instantiate model
model = VAE()


def loss_function(x_hat, x, mu, logvar, beta=0):
    MSE = nn.MSELoss()
    mse = MSE(x_hat, x)
    bce = nn.functional.binary_cross_entropy(
         x_hat, x, reduction='sum'
     )
    # KL divergence loss (the relative entropy between two distributions a multivariate gaussian and a normal)
    # (enforce a radius of 1 in each direction + pushing the means towards zero)
    kld = 0.5 * torch.sum(logvar.exp() - logvar - 1 + mu.pow(2))
    # print('bce = {}'.format(bce))
    # print('kld = {}'.format(kld))
    return bce + 0.0006*beta*kld, kld, bce, mse  # use beta to disentangle


def record_tensorboard(state, losses, accuracies, epoch):
    meanloss = np.mean(losses)
    meanaccuracy = np.mean(accuracies)
    writer.add_scalar("Loss/{}".format(state), meanloss, epoch)
    writer.add_scalar("Accuracy/{}".format(state), meanaccuracy, epoch)


def call_backs(lr, mean_accuracies, best_epoch, epoch, last_activation, sensitivity=0.0, cool_down=10, look_back=9):
    cb_flag = 0

    if mean_accuracies[epoch] < mean_accuracies[best_epoch]:
        best_epoch = epoch
        torch.save(model.state_dict(), 'C:/Users/William/Desktop/set 1/set{}.pt'.format(model_number))
    # is cool_down off?
    if last_activation < epoch - cool_down:
        # have enough values been input
        if epoch > look_back - 1:
            # test if mean of three old values is smaller than current value + sensitivity* value
            if np.mean(mean_accuracies[epoch-look_back:epoch-(look_back-3)]) < np.mean(mean_accuracies[epoch-2:epoch]) + sensitivity*np.mean(mean_accuracies[epoch-2:epoch]):
                lr = lr*0.2
                last_activation = epoch
                print('lowering lr to {}'.format(lr))
        if epoch > 3*look_back - 1:
            # test if mean of three old values is smaller than current value + sensitivity* value
            if np.mean(mean_accuracies[epoch-look_back*3:epoch-(look_back*3-3)]) < np.mean(mean_accuracies[epoch-2:epoch]) + sensitivity*np.mean(mean_accuracies[epoch-2:epoch]):
                cb_flag = 1
    return lr, last_activation, best_epoch, cb_flag


def train(lr):
    best_epoch = 0
    outputs = []
    mean_accuracies = []
    # Training loop
    last_activation = 0
    for epoch in range(num_epochs):
        print("Epoch %d" % epoch)

        #reduce lr as near optimum
        # if epoch <= num_epochs/5:
        #     lr = 0.002
        # elif epoch <= 2*num_epochs/5:
        #     lr = 0.001
        # elif epoch <= 3*num_epochs/5:
        #     lr = 0.0005
        # elif epoch <= 4*num_epochs/5:
        #     lr = 0.00025
        # else:
        #     lr = 0.000125
        model.train()
        optimizer = torch.optim.Adam(model.parameters(), lr=lr)
        i = 0

        losses = []
        losses_test = []
        accuracies = []
        accuracies_test = []
        kld_losses = []
        bce_losses = []

        for image, (label) in train_loader:
            # ===================forward=====================
            x_hat, mu, logvar = model(image)
            loss, kld_loss, bce_loss, accuracy = loss_function(x_hat, image, mu, logvar)
            losses.append(loss.item())
            accuracies.append(accuracy.item())
            kld_losses.append(kld_loss.item())
            bce_losses.append(bce_loss.item())

            # ===================backward====================
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

        print('kld loss (training): {}'.format(np.mean(kld_losses)))
        print('bce loss (training): {}'.format(np.mean(bce_losses)))

        record_tensorboard('train', losses, accuracies, epoch)

        model.eval()
        # test time
        for image, (label) in test_loader:
            # ===================forward=====================
            x_hat, mu, logvar = model(image)
            loss, kld_loss, bce_loss, accuracy = loss_function(x_hat, image, mu, logvar)
            losses_test.append(loss.item())

            accuracies_test.append(accuracy.item())

            if i == 0:

                writer.add_image("epoch{}/input".format(epoch), image[1].view(128, 128, 1), dataformats='HWC')
                writer.add_image("epoch{}/output".format(epoch), x_hat[1].view(128, 128, 1), dataformats='HWC')
            i += 1

        record_tensorboard('test', losses_test, accuracies_test, epoch)
        mean_accuracies.append(np.mean(accuracies_test))
        print('accuracy(testing): {}'.format(mean_accuracies[epoch].item()))
        outputs.append((epoch, image, x_hat))
        lr, last_activation, best_epoch, cb_flag = call_backs(lr, mean_accuracies, best_epoch, epoch, last_activation, 0.001)
        if cb_flag == 1:
            return outputs, epoch, best_epoch
    return outputs, epoch, best_epoch


writer.close()

outputs, final_epoch, best_epoch = train(lr)
print('best epoch was epoch {}, this state has been saved.'.format(best_epoch))


for k in range(0, final_epoch, int(math.floor(final_epoch/10))):
    plt.figure(figsize=(9, 2))
    plt.gray()
    imgs = outputs[k][1].detach().numpy()
    recon = outputs[k][2].detach().numpy()
    for i, item in enumerate(imgs):
        if i >= 9: break
        plt.subplot(2, 9, i + 1)
        # item = item.reshape(-1, 28,28) # -> use for Autoencoder_Linear
        # item: 1, 28, 28
        plt.imshow(item[0])

    for i, item in enumerate(recon):
        if i >= 9: break
        plt.subplot(2, 9, 9 + i + 1)  # row_length + i + 1
        # item = item.reshape(-1, 28,28) # -> use for Autoencoder_Linear
        # item: 1, 28, 28
        plt.imshow(item[0])

# best_img = outputs[best_epoch][1].detatch().numpy()
# best_recon = outputs[best_epoch][2].detatch().numpy()
#
# for i, item in enumerate(best_img):
#     if i >= 9: break
#     plt.subplot(2, 9, i + 1)
#     # item = item.reshape(-1, 28,28) # -> use for Autoencoder_Linear
#     # item: 1, 28, 28
#     plt.imshow(item[0])
#
# for i, item in enumerate(best_recon):
#     if i >= 9: break
#     plt.subplot(2, 9, 9 + i + 1)  # row_length + i + 1
#     # item = item.reshape(-1, 28,28) # -> use for Autoencoder_Linear
#     # item: 1, 28, 28
#     plt.imshow(item[0])

plt.show()
